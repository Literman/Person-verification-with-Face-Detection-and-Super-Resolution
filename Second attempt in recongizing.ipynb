{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "import random as rnd\n",
    "import itertools as it\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making pics info DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/lfw_funneled'\n",
    "\n",
    "pairs = ''\n",
    "with open(f'{path}/pairs.txt', 'r') as file:\n",
    "    pairs = file.read()\n",
    "\n",
    "df = pd.DataFrame(list(map(lambda x: x.split('\\t'), pairs.split('\\n')[1:301])), columns=['name', 'pic1', 'pic2'])\n",
    "df = (pd.melt(df, id_vars='name', value_vars=['pic1', 'pic2'], var_name='picNum', value_name='pic')\n",
    "        .drop('picNum', axis=1)\n",
    "        .sort_values(by=['name', 'pic'])\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "df['pic'] = df['pic'].apply(lambda x: x.zfill(4))\n",
    "df['path_x1'] = str(path) + '/' + df['name'] + '/' + df['name'] + '_' + df['pic'] + '.jpg'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_to_scale_path = df['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: x.split('/')[-1][:-4]+ '_result.jpg', pics_to_scale_path))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and adding path info to pics DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут надо самому ставить нужный скейл: 2 3 или 4. Так как памяти нехватает + настроить сохранение\n",
    "# в нужную папку сложна (не хочется заморачиваться), то надо перезапускать и руками переименовывать папку.\n",
    "\n",
    "scaled_pics = os.listdir('dataset/output')\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_path):\n",
    "    if pic in scaled_pics:\n",
    "        continue\n",
    "    abc = f'--file={pic_path} --scale=4'\n",
    "    %run sr.py {abc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in [2, 3, 4]:\n",
    "    df[f'path_x{scale}'] = f'dataset/output_x{scale}/'+df[f'path_x1'].apply(lambda x: x.split('/')[-1][:-4])+'_result.jpg'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pics_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making DataFrame for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pics_df.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получим всевозможные пары фоточек для каждого человека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data_sim = []\n",
    "for name, name_df in df[['name', 'pic']].groupby('name'):\n",
    "    pics = name_df['pic'].values\n",
    "    pics_comb = list(it.combinations(pics, 2))\n",
    "    pics_name_comb = list(map(lambda x: [name]+list(x), pics_comb))\n",
    "    for comb in pics_name_comb:\n",
    "        classification_data_sim.append(comb)\n",
    "classification_df_sim = pd.DataFrame(classification_data_sim, columns=['name', 'pic1', 'pic2'])\n",
    "classification_df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pic_num in [1, 2]:\n",
    "    classification_df_sim = (pd.merge(classification_df_sim, df, \n",
    "                                      left_on=['name', f'pic{pic_num}'], right_on=['name', 'pic'], \n",
    "                                      how='left', suffixes=('_1', '_2')))\n",
    "classification_df_sim.drop(['pic_1', 'pic_2'], axis=1, inplace=True)\n",
    "classification_df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df_sim.to_csv('classification_similar_people_pics_df.csv')\n",
    "print(f'We\\'ve got {classification_df_sim.shape[0]} pairs of pics with similar persons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### И столько же для разных людей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_sim_people_pics = [el for el in it.combinations(df[['name', 'pic']].values.tolist(), 2) if el[0][0] != el[1][0]]\n",
    "non_sim_people_pics = [el[0]+el[1] for el in non_sim_people_pics]\n",
    "non_sim_people_pics = rnd.sample(non_sim_people_pics, classification_df_sim.shape[0])\n",
    "classification_df_nonsim = pd.DataFrame(non_sim_people_pics, columns=['name1', 'pic1', 'name2', 'pic2'])\n",
    "classification_df_nonsim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic_num in [1, 2]:\n",
    "    classification_df_nonsim = (pd.merge(classification_df_nonsim, df, \n",
    "                                      left_on=[f'name{pic_num}', f'pic{pic_num}'], right_on=['name', 'pic'], \n",
    "                                      how='left', suffixes=('_1', '_2')))\n",
    "classification_df_nonsim.drop(['name_1', 'pic_1', 'name_2', 'pic_2'], axis=1, inplace=True)\n",
    "classification_df_nonsim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df_nonsim.to_csv('classification_non-similar_people_pics_df.csv')\n",
    "print(f'And {classification_df_nonsim.shape[0]} pairs of pics with non-similar persons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer import Recognizer\n",
    "from skimage.io import imread\n",
    "\n",
    "THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nikita\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Restoring parameters from ./facenet_models/facenet/model-20180408-102900.ckpt-90\n"
     ]
    }
   ],
   "source": [
    "recognizer = Recognizer()\n",
    "\n",
    "def recongize(row):\n",
    "    photo1 = imread(row.ix[0])\n",
    "    photo2 = imread(row.ix[1])\n",
    "    similarity = recognizer.get_best_similarity(photo1, photo2)\n",
    "    return similarity < THRESHOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar and non-similar people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similar = pd.read_csv('classification_similar_people_pics_df.csv', index_col=0)\n",
    "data_nonsimilar = pd.read_csv('classification_non-similar_people_pics_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2019-05-02 23:39:42.658064\n",
      "Scale x1 is done in 0:03:43.563873\n",
      "Scale x2 is done in 0:08:56.335615\n",
      "Scale x3 is done in 0:16:53.689556\n",
      "Scale x4 is done in 0:27:20.152157\n",
      "Scale x1 is done in 0:03:37.578908\n",
      "Scale x2 is done in 0:08:45.188431\n",
      "Scale x3 is done in 0:16:28.823655\n",
      "Scale x4 is done in 0:27:13.626479\n",
      "Wall time: 1h 52min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(f'Started at {datetime.now()}')\n",
    "for data in [data_similar, data_nonsimilar]:\n",
    "    for scale in [1, 2, 3, 4]:\n",
    "        start = datetime.now()\n",
    "        data[f'rec_x{scale}'] = data[[f'path_x{scale}_1', f'path_x{scale}_2']].apply(recongize, axis=1)\n",
    "        print(f'Scale x{scale} is done in {datetime.now() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similar.to_csv('classification_similar_people_pics_df.csv')\n",
    "data_nonsimilar.to_csv('classification_non-similar_people_pics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_type</th>\n",
       "      <th>scale</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Similar</td>\n",
       "      <td>x1</td>\n",
       "      <td>80.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Similar</td>\n",
       "      <td>x2</td>\n",
       "      <td>83.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Similar</td>\n",
       "      <td>x3</td>\n",
       "      <td>83.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Similar</td>\n",
       "      <td>x4</td>\n",
       "      <td>83.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Non-Similar</td>\n",
       "      <td>x1</td>\n",
       "      <td>65.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Non-Similar</td>\n",
       "      <td>x2</td>\n",
       "      <td>61.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Non-Similar</td>\n",
       "      <td>x3</td>\n",
       "      <td>60.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Non-Similar</td>\n",
       "      <td>x4</td>\n",
       "      <td>60.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>x1</td>\n",
       "      <td>73.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>x2</td>\n",
       "      <td>72.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>x3</td>\n",
       "      <td>72.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>x4</td>\n",
       "      <td>72.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    person_type scale  accuracy\n",
       "0       Similar    x1     80.94\n",
       "1       Similar    x2     83.21\n",
       "2       Similar    x3     83.93\n",
       "3       Similar    x4     83.81\n",
       "4   Non-Similar    x1     65.59\n",
       "5   Non-Similar    x2     61.27\n",
       "6   Non-Similar    x3     60.91\n",
       "7   Non-Similar    x4     60.91\n",
       "8         Mixed    x1     73.26\n",
       "9         Mixed    x2     72.24\n",
       "10        Mixed    x3     72.42\n",
       "11        Mixed    x4     72.36"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def counts_pct(col):\n",
    "    return round(col.value_counts(normalize=True) * 100, 2)\n",
    "\n",
    "classification_results = pd.DataFrame()\n",
    "classification_results['person_type'] = ['Similar'] * 4 + ['Non-Similar'] * 4 + ['Mixed'] * 4\n",
    "classification_results['scale'] = ['x1', 'x2', 'x3', 'x4'] * 3\n",
    "\n",
    "recs = ['rec_x1', 'rec_x2', 'rec_x3', 'rec_x4']\n",
    "recs_sim = data_similar[recs]\n",
    "recs_nonsim = data_nonsimilar[recs].replace({True: False, False: True})\n",
    "classification_results['accuracy'] = (list(recs_sim.apply(counts_pct).loc[True].values) + \n",
    "                                      list(recs_nonsim.apply(counts_pct).loc[True].values) +\n",
    "                                      list(pd.concat([recs_sim, recs_nonsim]).apply(counts_pct).loc[True].values))\n",
    "\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results.to_csv('classification_results_DCSCN.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
