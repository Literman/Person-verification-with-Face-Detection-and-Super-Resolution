{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making pics info DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/lfw_funneled'\n",
    "\n",
    "pairs = ''\n",
    "with open(f'{path}/pairs.txt', 'r') as file:\n",
    "    pairs = file.read()\n",
    "\n",
    "df = pd.DataFrame(list(map(lambda x: x.split('\\t'), pairs.split('\\n')[1:301])), columns=['name', 'pic1', 'pic2'])\n",
    "df = (pd.melt(df, id_vars='name', value_vars=['pic1', 'pic2'], var_name='picNum', value_name='pic')\n",
    "        .drop('picNum', axis=1)\n",
    "        .sort_values(by=['name', 'pic'])\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "df['pic'] = df['pic'].apply(lambda x: x.zfill(4))\n",
    "df['path_x1'] = str(path) + '/' + df['name'] + '/' + df['name'] + '_' + df['pic'] + '.jpg'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_to_scale_path = df['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: x.split('/')[-1][:-4]+ '_result.jpg', pics_to_scale_path))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and adding path info to pics DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут надо самому ставить нужный скейл: 2 3 или 4. Так как памяти нехватает + настроить сохранение\n",
    "# в нужную папку сложна (не хочется заморачиваться), то надо перезапускать и руками переименовывать папку.\n",
    "scaled_pics = os.listdir('dataset/output')\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_path):\n",
    "    if pic in scaled_pics:\n",
    "        continue\n",
    "    abc = f'--file={pic_path} --scale=4'\n",
    "    %run sr.py {abc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in [2, 3, 4]:\n",
    "    df[f'path_x{scale}'] = f'dataset/output_x{scale}/' + df[f'path_x1'].apply(lambda x: x.split('/')[-1][:-4]) + '_result.jpg'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pics_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making DataFrame for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получили всевозможные пары фоточек для каждого человека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = []\n",
    "for name, name_df in df[['name', 'pic']].groupby('name'):\n",
    "    pics = name_df['pic'].values\n",
    "    pics_comb = list(it.combinations(pics, 2))\n",
    "    pics_name_comb = list(map(lambda x: [name]+list(x), pics_comb))\n",
    "    for comb in pics_name_comb:\n",
    "        classification_data.append(comb)\n",
    "classification_df = pd.DataFrame(classification_data, columns=['name', 'pic1', 'pic2'])\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pic_num in [1, 2]:\n",
    "    classification_df = (pd.merge(classification_df, df, \n",
    "                                  left_on=['name', f'pic{pic_num}'], right_on=['name', 'pic'], \n",
    "                                  how='left', suffixes=('_1', '_2')))\n",
    "classification_df.drop(['pic_1', 'pic_2'], axis=1, inplace=True)\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df.to_csv('classification_pics_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer import Recognizer\n",
    "from skimage.io import imread\n",
    "\n",
    "THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pic1</th>\n",
       "      <th>pic2</th>\n",
       "      <th>path_x1_1</th>\n",
       "      <th>path_x2_1</th>\n",
       "      <th>path_x3_1</th>\n",
       "      <th>path_x4_1</th>\n",
       "      <th>path_x1_2</th>\n",
       "      <th>path_x2_2</th>\n",
       "      <th>path_x3_2</th>\n",
       "      <th>path_x4_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abel_Pacheco</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco...</td>\n",
       "      <td>dataset/output_x2/Abel_Pacheco_0001_result.jpg</td>\n",
       "      <td>dataset/output_x3/Abel_Pacheco_0001_result.jpg</td>\n",
       "      <td>dataset/output_x4/Abel_Pacheco_0001_result.jpg</td>\n",
       "      <td>dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco...</td>\n",
       "      <td>dataset/output_x2/Abel_Pacheco_0004_result.jpg</td>\n",
       "      <td>dataset/output_x3/Abel_Pacheco_0004_result.jpg</td>\n",
       "      <td>dataset/output_x4/Abel_Pacheco_0004_result.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Akhmed_Zakayev</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "      <td>dataset/output_x2/Akhmed_Zakayev_0001_result.jpg</td>\n",
       "      <td>dataset/output_x3/Akhmed_Zakayev_0001_result.jpg</td>\n",
       "      <td>dataset/output_x4/Akhmed_Zakayev_0001_result.jpg</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "      <td>dataset/output_x2/Akhmed_Zakayev_0002_result.jpg</td>\n",
       "      <td>dataset/output_x3/Akhmed_Zakayev_0002_result.jpg</td>\n",
       "      <td>dataset/output_x4/Akhmed_Zakayev_0002_result.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akhmed_Zakayev</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "      <td>dataset/output_x2/Akhmed_Zakayev_0001_result.jpg</td>\n",
       "      <td>dataset/output_x3/Akhmed_Zakayev_0001_result.jpg</td>\n",
       "      <td>dataset/output_x4/Akhmed_Zakayev_0001_result.jpg</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "      <td>dataset/output_x2/Akhmed_Zakayev_0003_result.jpg</td>\n",
       "      <td>dataset/output_x3/Akhmed_Zakayev_0003_result.jpg</td>\n",
       "      <td>dataset/output_x4/Akhmed_Zakayev_0003_result.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akhmed_Zakayev</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "      <td>dataset/output_x2/Akhmed_Zakayev_0002_result.jpg</td>\n",
       "      <td>dataset/output_x3/Akhmed_Zakayev_0002_result.jpg</td>\n",
       "      <td>dataset/output_x4/Akhmed_Zakayev_0002_result.jpg</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "      <td>dataset/output_x2/Akhmed_Zakayev_0003_result.jpg</td>\n",
       "      <td>dataset/output_x3/Akhmed_Zakayev_0003_result.jpg</td>\n",
       "      <td>dataset/output_x4/Akhmed_Zakayev_0003_result.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amber_Tamblyn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>dataset/lfw_funneled/Amber_Tamblyn/Amber_Tambl...</td>\n",
       "      <td>dataset/output_x2/Amber_Tamblyn_0001_result.jpg</td>\n",
       "      <td>dataset/output_x3/Amber_Tamblyn_0001_result.jpg</td>\n",
       "      <td>dataset/output_x4/Amber_Tamblyn_0001_result.jpg</td>\n",
       "      <td>dataset/lfw_funneled/Amber_Tamblyn/Amber_Tambl...</td>\n",
       "      <td>dataset/output_x2/Amber_Tamblyn_0002_result.jpg</td>\n",
       "      <td>dataset/output_x3/Amber_Tamblyn_0002_result.jpg</td>\n",
       "      <td>dataset/output_x4/Amber_Tamblyn_0002_result.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  pic1  pic2  \\\n",
       "0    Abel_Pacheco     1     4   \n",
       "1  Akhmed_Zakayev     1     2   \n",
       "2  Akhmed_Zakayev     1     3   \n",
       "3  Akhmed_Zakayev     2     3   \n",
       "4   Amber_Tamblyn     1     2   \n",
       "\n",
       "                                           path_x1_1  \\\n",
       "0  dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco...   \n",
       "1  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...   \n",
       "2  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...   \n",
       "3  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...   \n",
       "4  dataset/lfw_funneled/Amber_Tamblyn/Amber_Tambl...   \n",
       "\n",
       "                                          path_x2_1  \\\n",
       "0    dataset/output_x2/Abel_Pacheco_0001_result.jpg   \n",
       "1  dataset/output_x2/Akhmed_Zakayev_0001_result.jpg   \n",
       "2  dataset/output_x2/Akhmed_Zakayev_0001_result.jpg   \n",
       "3  dataset/output_x2/Akhmed_Zakayev_0002_result.jpg   \n",
       "4   dataset/output_x2/Amber_Tamblyn_0001_result.jpg   \n",
       "\n",
       "                                          path_x3_1  \\\n",
       "0    dataset/output_x3/Abel_Pacheco_0001_result.jpg   \n",
       "1  dataset/output_x3/Akhmed_Zakayev_0001_result.jpg   \n",
       "2  dataset/output_x3/Akhmed_Zakayev_0001_result.jpg   \n",
       "3  dataset/output_x3/Akhmed_Zakayev_0002_result.jpg   \n",
       "4   dataset/output_x3/Amber_Tamblyn_0001_result.jpg   \n",
       "\n",
       "                                          path_x4_1  \\\n",
       "0    dataset/output_x4/Abel_Pacheco_0001_result.jpg   \n",
       "1  dataset/output_x4/Akhmed_Zakayev_0001_result.jpg   \n",
       "2  dataset/output_x4/Akhmed_Zakayev_0001_result.jpg   \n",
       "3  dataset/output_x4/Akhmed_Zakayev_0002_result.jpg   \n",
       "4   dataset/output_x4/Amber_Tamblyn_0001_result.jpg   \n",
       "\n",
       "                                           path_x1_2  \\\n",
       "0  dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco...   \n",
       "1  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...   \n",
       "2  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...   \n",
       "3  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...   \n",
       "4  dataset/lfw_funneled/Amber_Tamblyn/Amber_Tambl...   \n",
       "\n",
       "                                          path_x2_2  \\\n",
       "0    dataset/output_x2/Abel_Pacheco_0004_result.jpg   \n",
       "1  dataset/output_x2/Akhmed_Zakayev_0002_result.jpg   \n",
       "2  dataset/output_x2/Akhmed_Zakayev_0003_result.jpg   \n",
       "3  dataset/output_x2/Akhmed_Zakayev_0003_result.jpg   \n",
       "4   dataset/output_x2/Amber_Tamblyn_0002_result.jpg   \n",
       "\n",
       "                                          path_x3_2  \\\n",
       "0    dataset/output_x3/Abel_Pacheco_0004_result.jpg   \n",
       "1  dataset/output_x3/Akhmed_Zakayev_0002_result.jpg   \n",
       "2  dataset/output_x3/Akhmed_Zakayev_0003_result.jpg   \n",
       "3  dataset/output_x3/Akhmed_Zakayev_0003_result.jpg   \n",
       "4   dataset/output_x3/Amber_Tamblyn_0002_result.jpg   \n",
       "\n",
       "                                          path_x4_2  \n",
       "0    dataset/output_x4/Abel_Pacheco_0004_result.jpg  \n",
       "1  dataset/output_x4/Akhmed_Zakayev_0002_result.jpg  \n",
       "2  dataset/output_x4/Akhmed_Zakayev_0003_result.jpg  \n",
       "3  dataset/output_x4/Akhmed_Zakayev_0003_result.jpg  \n",
       "4   dataset/output_x4/Amber_Tamblyn_0002_result.jpg  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('classification_pics_df.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nikita\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Restoring parameters from ./facenet_models/facenet/model-20180408-102900.ckpt-90\n"
     ]
    }
   ],
   "source": [
    "recognizer = Recognizer()\n",
    "\n",
    "def recongize(row):\n",
    "    photo1 = imread(row.ix[0])\n",
    "    photo2 = imread(row.ix[1])\n",
    "    similarity = recognizer.get_best_similarity(photo1, photo2)\n",
    "    return similarity < THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale x1 is done.\n",
      "Scale x2 is done.\n",
      "Scale x3 is done.\n",
      "Scale x4 is done.\n",
      "Wall time: 56min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for scale in [1, 2, 3, 4]:\n",
    "    data[f'rec_x{scale}'] = data[[f'path_x{scale}_1', f'path_x{scale}_2']].apply(recongize, axis=1)\n",
    "    print(f'Scale x{scale} is done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x1</td>\n",
       "      <td>80.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x2</td>\n",
       "      <td>83.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x3</td>\n",
       "      <td>83.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x4</td>\n",
       "      <td>83.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  scale  accuracy\n",
       "0    x1     80.94\n",
       "1    x2     83.21\n",
       "2    x3     83.93\n",
       "3    x4     83.81"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_results = pd.DataFrame(['x1', 'x2', 'x3', 'x4'], columns=['scale'])\n",
    "classification_results['accuracy'] = (data[['rec_x1', 'rec_x2', 'rec_x3', 'rec_x4']]\n",
    "                                      .apply(lambda col: round(col.value_counts(normalize=True) * 100, 2))\n",
    "                                      .iloc[0].values)\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results.to_csv('classification_results_DCSCN.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
