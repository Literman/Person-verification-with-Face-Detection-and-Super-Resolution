{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os \n",
    "from datetime import datetime\n",
    "import random as rnd\n",
    "import itertools as it\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making pics info DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basename(path): # dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco_0001.JPG -> Abel_Pacheco_0001\n",
    "    return os.path.splitext(os.path.basename(path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>pic</th>\n",
       "      <th>path_x1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abel_Pacheco</td>\n",
       "      <td>0001</td>\n",
       "      <td>dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abel_Pacheco</td>\n",
       "      <td>0004</td>\n",
       "      <td>dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akhmed_Zakayev</td>\n",
       "      <td>0001</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akhmed_Zakayev</td>\n",
       "      <td>0002</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akhmed_Zakayev</td>\n",
       "      <td>0003</td>\n",
       "      <td>dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name   pic                                            path_x1\n",
       "0    Abel_Pacheco  0001  dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco...\n",
       "1    Abel_Pacheco  0004  dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco...\n",
       "2  Akhmed_Zakayev  0001  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...\n",
       "3  Akhmed_Zakayev  0002  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak...\n",
       "4  Akhmed_Zakayev  0003  dataset/lfw_funneled/Akhmed_Zakayev/Akhmed_Zak..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'dataset/lfw_funneled'\n",
    "\n",
    "pairs = ''\n",
    "with open(f'{path}/pairs.txt', 'r') as file:\n",
    "    pairs = file.read()\n",
    "\n",
    "df = pd.DataFrame(list(map(lambda x: x.split('\\t'), pairs.split('\\n')[1:301])), columns=['name', 'pic1', 'pic2'])\n",
    "df = (pd.melt(df, id_vars='name', value_vars=['pic1', 'pic2'], var_name='picNum', value_name='pic')\n",
    "        .drop('picNum', axis=1)\n",
    "        .sort_values(by=['name', 'pic'])\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "df['pic'] = df['pic'].apply(lambda x: x.zfill(4))\n",
    "df['path_x1'] = str(path) + '/' + df['name'] + '/' + df['name'] + '_' + df['pic'] + '.jpg'\n",
    "df.to_csv('pics_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 500 unique pics to be scaled\n"
     ]
    }
   ],
   "source": [
    "pics_to_scale_path = df['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: get_basename(x) + '_result.jpg', pics_to_scale_path))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling with DCSCN and adding path info to pics DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут надо самому ставить нужный скейл: 2 3 или 4. Так как памяти нехватает + настроить сохранение\n",
    "# в нужную папку сложна (не хочется заморачиваться), то надо перезапускать и руками переименовывать папку.\n",
    "\n",
    "scale = 4\n",
    "scaled_pics = os.listdir(f'dataset/output_DCSCN_x{scale}')\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_path):\n",
    "    if pic in scaled_pics:\n",
    "        continue\n",
    "    abc = f'--file={pic_path} --scale={scale}'\n",
    "    %run sr.py {abc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in [2, 3, 4]:\n",
    "    df[f'path_x{scale}'] = f'dataset/output_DCSCN_x{scale}/'+df[f'path_x1'].apply(get_basename)+'_result.jpg'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('pics_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making DataFrame for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pics_df.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Получим всевозможные пары фоточек для каждого человека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data_sim = []\n",
    "for name, name_df in df[['name', 'pic']].groupby('name'):\n",
    "    pics = name_df['pic'].values\n",
    "    pics_comb = list(it.combinations(pics, 2))\n",
    "    pics_name_comb = list(map(lambda x: [name]+list(x), pics_comb))\n",
    "    for comb in pics_name_comb:\n",
    "        classification_data_sim.append(comb)\n",
    "classification_df_sim = pd.DataFrame(classification_data_sim, columns=['name', 'pic1', 'pic2'])\n",
    "classification_df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pic_num in [1, 2]:\n",
    "    classification_df_sim = (pd.merge(classification_df_sim, df, \n",
    "                                      left_on=['name', f'pic{pic_num}'], right_on=['name', 'pic'], \n",
    "                                      how='left', suffixes=('_1', '_2')))\n",
    "classification_df_sim.drop(['pic_1', 'pic_2'], axis=1, inplace=True)\n",
    "classification_df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df_sim.to_csv('classification_similar_people_pics_df.csv')\n",
    "print(f'We\\'ve got {classification_df_sim.shape[0]} pairs of pics with similar persons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### И столько же для разных людей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_sim_people_pics = [el for el in it.combinations(df[['name', 'pic']].values.tolist(), 2) if el[0][0] != el[1][0]]\n",
    "non_sim_people_pics = [el[0]+el[1] for el in non_sim_people_pics]\n",
    "non_sim_people_pics = rnd.sample(non_sim_people_pics, classification_df_sim.shape[0])\n",
    "classification_df_nonsim = pd.DataFrame(non_sim_people_pics, columns=['name1', 'pic1', 'name2', 'pic2'])\n",
    "classification_df_nonsim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pic_num in [1, 2]:\n",
    "    classification_df_nonsim = (pd.merge(classification_df_nonsim, df, \n",
    "                                      left_on=[f'name{pic_num}', f'pic{pic_num}'], right_on=['name', 'pic'], \n",
    "                                      how='left', suffixes=('_1', '_2')))\n",
    "classification_df_nonsim.drop(['name_1', 'pic_1', 'name_2', 'pic_2'], axis=1, inplace=True)\n",
    "classification_df_nonsim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df_nonsim.to_csv('classification_non-similar_people_pics_df.csv')\n",
    "print(f'And {classification_df_nonsim.shape[0]} pairs of pics with non-similar persons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification DCSCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recognizer import Recognizer\n",
    "from skimage.io import imread\n",
    "\n",
    "THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recognizer = Recognizer()\n",
    "\n",
    "def recongize(row):\n",
    "    photo1 = imread(row.ix[0])\n",
    "    photo2 = imread(row.ix[1])\n",
    "    similarity = recognizer.get_best_similarity(photo1, photo2)\n",
    "    return similarity < THRESHOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar and non-similar people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similar = pd.read_csv('classification_similar_people_pics_df.csv', index_col=0)\n",
    "data_nonsimilar = pd.read_csv('classification_non-similar_people_pics_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f'Started at {datetime.now()}')\n",
    "for data in [data_similar, data_nonsimilar]:\n",
    "    for scale in [1, 2, 3, 4]:\n",
    "        start = datetime.now()\n",
    "        data[f'rec_x{scale}'] = data[[f'path_x{scale}_1', f'path_x{scale}_2']].apply(recongize, axis=1)\n",
    "        print(f'Scale x{scale} is done in {datetime.now() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_similar.to_csv('classification_similar_people_pics_df.csv')\n",
    "data_nonsimilar.to_csv('classification_non-similar_people_pics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def counts_pct(col):\n",
    "    return round(col.value_counts(normalize=True) * 100, 2)\n",
    "\n",
    "classification_results = pd.DataFrame()\n",
    "classification_results['person_type'] = ['Similar'] * 4 + ['Non-Similar'] * 4 + ['Mixed'] * 4\n",
    "classification_results['scale'] = ['x1', 'x2', 'x3', 'x4'] * 3\n",
    "\n",
    "recs = ['rec_x1', 'rec_x2', 'rec_x3', 'rec_x4']\n",
    "recs_sim = data_similar[recs]\n",
    "recs_nonsim = data_nonsimilar[recs].replace({True: False, False: True})\n",
    "classification_results['accuracy'] = (list(recs_sim.apply(counts_pct).loc[True].values) + \n",
    "                                      list(recs_nonsim.apply(counts_pct).loc[True].values) +\n",
    "                                      list(pd.concat([recs_sim, recs_nonsim]).apply(counts_pct).loc[True].values))\n",
    "\n",
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results.to_csv('classification_results_DCSCN.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling with ESRGAN and adding path info to pics DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import ESRGAN.architecture as arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'ESRGAN/models/RRDB_ESRGAN_x4.pth' # sys.argv[1]  # models/RRDB_ESRGAN_x4.pth OR models/RRDB_PSNR_x4.pth\n",
    "device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n",
    "\n",
    "model = arch.RRDB_Net(3, 3, 64, 23, gc=32, upscale=4, norm_type=None, act_type='leakyrelu', \n",
    "                      mode='CNA', res_scale=1, upsample_mode='upconv')\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 4\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_path):\n",
    "    img = cv2.imread(pic_path, cv2.IMREAD_COLOR)\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round()\n",
    "    cv2.imwrite(f'dataset/output_ESRGAN_x4/{pic}', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
