{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run <b>3 cells below</b> and then <b>after <i>Up-Scale and get perfomance of your models</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import sys\n",
    "import os \n",
    "from datetime import datetime\n",
    "import random as rnd\n",
    "import itertools as it\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "from RECOGNIZER.recognizer import Recognizer\n",
    "from skimage.io import imread\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basename(path): # dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco_0001.JPG -> Abel_Pacheco_0001\n",
    "    return os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "def add_pathes(df, scales, model_name): # (df, [2, 3, 4], 'DCSCN')\n",
    "    for scale in scales:\n",
    "        df[f'path_x{scale}'] = f'{model_name}/output_x{scale}/' + df[f'path_x1'].apply(get_basename) + '_result.jpg'\n",
    "    return df\n",
    "\n",
    "def get_pathes(classification_df, df):\n",
    "    for pic_num in [1, 2]:\n",
    "        classification_df = (pd.merge(classification_df, df, \n",
    "                                      left_on=[f'name_{pic_num}', f'pic_{pic_num}'], right_on=['name', 'pic'], \n",
    "                                      how='left', suffixes=('_1', '_2')))\n",
    "    classification_df = classification_df.loc[:, ~classification_df.columns.duplicated()]\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_pics(classification_df, scales):\n",
    "    initial_time = datetime.now() \n",
    "    print(f'Started at {initial_time}')\n",
    "\n",
    "    recognizer = Recognizer()\n",
    "    THRESHOLD = 0.9\n",
    "    \n",
    "    def recongize(row):\n",
    "        photo1 = imread(row.ix[0])\n",
    "        photo2 = imread(row.ix[1])\n",
    "        similarity = recognizer.get_best_similarity(photo1, photo2)\n",
    "        return 1 if similarity < THRESHOLD else 0\n",
    "\n",
    "    for scale in scales:\n",
    "        start = datetime.now()\n",
    "        print(f'Scale x{scale} started at {start}')\n",
    "        classification_df[f'rec_x{scale}'] = classification_df[[f'path_x{scale}_1', f'path_x{scale}_2']].apply(recongize, axis=1)\n",
    "        print(f'Scale x{scale} is done in {datetime.now() - start}')\n",
    "    print(f'Ended in {datetime.now() - initial_time}')\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a DataFrame with paths to unique pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/'\n",
    "\n",
    "pairs = ''\n",
    "with open(f'{dataset_path}pairs.txt', 'r') as file:\n",
    "    pairs = file.read()\n",
    "\n",
    "df = pd.DataFrame(list(map(lambda x: x.split('\\t'), pairs.split('\\n')[1:301])), columns=['name', 'pic1', 'pic2'])\n",
    "df = (pd.melt(df, id_vars='name', value_vars=['pic1', 'pic2'], var_name='picNum', value_name='pic')\n",
    "        .drop('picNum', axis=1)\n",
    "        .sort_values(by=['name', 'pic'])\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "df['pic'] = df['pic'].apply(lambda x: x.zfill(4))\n",
    "df['path_x1'] = str(dataset_path) + df['name'] + '/' + df['name'] + '_' + df['pic'] + '.jpg'\n",
    "\n",
    "df.to_csv('pics_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_to_scale_paths = df['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: get_basename(x) + '_result.jpg', pics_to_scale_paths))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating regular DataFrame for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_people_pics = []\n",
    "for name, name_df in df[['name', 'pic']].groupby('name'):\n",
    "    pics = name_df['pic'].values\n",
    "    pics_comb = list(it.combinations(pics, 2))\n",
    "    pics_name_comb = list(map(lambda x: [name]+[x[0]]+[name]+[x[1]], pics_comb))\n",
    "    for comb in pics_name_comb:\n",
    "        sim_people_pics.append(comb+[1])\n",
    "\n",
    "non_sim_people_pics = [el for el in it.combinations(df[['name', 'pic']].values.tolist(), 2) if el[0][0] != el[1][0]]\n",
    "non_sim_people_pics = [el[0]+el[1]+[0] for el in non_sim_people_pics]\n",
    "non_sim_people_pics = rnd.sample(non_sim_people_pics, len(sim_people_pics))\n",
    "\n",
    "classification_df = pd.DataFrame(sim_people_pics+non_sim_people_pics, \n",
    "                                 columns=['name_1', 'pic_1', 'name_2', 'pic_2', 'similarity'])\n",
    "\n",
    "classification_df.to_csv('classification_df.csv')\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = get_pathes(classification_df, df)\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_df = recognize_pics(classification_df, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df.to_csv('classification_df.csv')\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up-Scale and get perfomance of your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-Scale funcs of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can up-scale pics with different models and look at it's perfomance in recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_to_scale_paths = pd.read_csv('pics_df.csv', usecols=['path_x1'])['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: get_basename(x) + '_result.jpg', pics_to_scale_paths))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель DCSCN \n",
    "# Тут надо самому ставить нужный скейл: 2 3 или 4, так как памяти не хватает + настроить сохранение\n",
    "# в нужную папку сложна (не хочется заморачиваться), то надо перезапускать и руками переименовывать папку.\n",
    "\n",
    "model_name = 'DCSCN'\n",
    "scales = 4\n",
    "scaled_pics = os.listdir(f'{model_name}/output') # папка, в которой должны находиться апскейленные пикчи\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_paths):\n",
    "    if pic in scaled_pics: # зачастую случается OOM и чтобы заново не апскейлить уже апскейленные пикчи, чекаем их\n",
    "        continue\n",
    "    abc = f'--file={pic_path} --scale={scale}'\n",
    "    %run sr.py {abc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель ESRGAN\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import ESRGAN.architecture as arch\n",
    "\n",
    "model_path = 'ESRGAN/models/RRDB_ESRGAN_x4.pth' # sys.argv[1]  # models/RRDB_ESRGAN_x4.pth OR models/RRDB_PSNR_x4.pth\n",
    "device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n",
    "\n",
    "model = arch.RRDB_Net(3, 3, 64, 23, gc=32, upscale=4, norm_type=None, act_type='leakyrelu', \n",
    "                      mode='CNA', res_scale=1, upsample_mode='upconv')\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)\n",
    "\n",
    "scale = 4\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_paths):\n",
    "    img = cv2.imread(pic_path, cv2.IMREAD_COLOR)\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round()\n",
    "    cv2.imwrite(f'dataset/output_ESRGAN_x4/{pic}', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recognition perfomance of your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_perfomance(model_name, scales):\n",
    "    pics_df = pd.read_csv('pics_df.csv', index_col=0, dtype='object')\n",
    "    classification_df = pd.read_csv('classification_df.csv', index_col=0, dtype='object')\n",
    "    \n",
    "    model_pics_df = add_pathes(pics_df, scales, model_name)\n",
    "    model_classification_df = get_pathes(classification_df, model_pics_df)\n",
    "    \n",
    "    model_classification_df = recognize_pics(model_classification_df, scales)\n",
    "    model_classification_df.to_csv(f'classification_df_{model_name}.csv')\n",
    "    return model_classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2019-05-05 15:57:53.550833\n",
      "INFO:tensorflow:Restoring parameters from RECOGNIZER/facenet_models/facenet/model-20180408-102900.ckpt-90\n",
      "Scale x2 started at 2019-05-05 15:58:17.661978\n",
      "Scale x2 is done in 0:17:49.287297\n",
      "Scale x3 started at 2019-05-05 16:16:06.949275\n",
      "Scale x3 is done in 0:32:38.509580\n",
      "Scale x4 started at 2019-05-05 16:48:45.458855\n",
      "Scale x4 is done in 0:51:58.504677\n",
      "Ended in 1:42:50.412699\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DCSCN'\n",
    "scales = [2, 3, 4]\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2019-05-05 14:59:15.204908\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Coding\\Person recognizer with Face Detection and Super-Resolution\\RECOGNIZER\\MTCNN\\layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from RECOGNIZER/facenet_models/facenet/model-20180408-102900.ckpt-90\n",
      "Scale x4 started at 2019-05-05 14:59:38.889833\n",
      "Scale x4 is done in 0:52:33.752833\n",
      "Ended in 0:52:57.437758\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ESRGAN'\n",
    "scales = [4]\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
