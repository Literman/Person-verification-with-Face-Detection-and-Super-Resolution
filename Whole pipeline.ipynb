{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run <b>3 cells below</b> and then <b>after <i>Up-Scale and get perfomance of your models</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "import sys\n",
    "import os \n",
    "from datetime import datetime\n",
    "import random as rnd\n",
    "import itertools as it\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "from RECOGNIZER.recognizer import Recognizer\n",
    "from skimage.io import imread\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basename(path): # dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco_0001.JPG -> Abel_Pacheco_0001\n",
    "    return os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "def add_pathes(df, scales, model_name): # (df, [2, 3, 4], 'DCSCN')\n",
    "    for scale in scales:\n",
    "        df[f'path_x{scale}'] = f'{model_name}/output_x{scale}/' + df[f'path_x1'].apply(get_basename) + '_result.jpg'\n",
    "    return df\n",
    "\n",
    "def get_pathes(classification_df, df):\n",
    "    for pic_num in [1, 2]:\n",
    "        classification_df = (pd.merge(classification_df, df, \n",
    "                                      left_on=[f'name_{pic_num}', f'pic_{pic_num}'], right_on=['name', 'pic'], \n",
    "                                      how='left', suffixes=('_1', '_2')))\n",
    "    classification_df = classification_df.loc[:, ~classification_df.columns.duplicated()]\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_pics(classification_df, scales):\n",
    "    initial_time = datetime.now() \n",
    "    print(f'Started at {initial_time}')\n",
    "\n",
    "    recognizer = Recognizer()\n",
    "    THRESHOLD = 0.9\n",
    "    \n",
    "    def recongize(row):\n",
    "        photo1 = imread(row.ix[0])\n",
    "        photo2 = imread(row.ix[1])\n",
    "        similarity = recognizer.get_best_similarity(photo1, photo2)\n",
    "        return 1 if similarity < THRESHOLD else 0\n",
    "\n",
    "    for scale in scales:\n",
    "        start = datetime.now()\n",
    "        print(f'Scale x{scale} started at {start}')\n",
    "        classification_df[f'rec_x{scale}'] = classification_df[[f'path_x{scale}_1', f'path_x{scale}_2']].apply(recongize, axis=1)\n",
    "        print(f'Scale x{scale} is done in {datetime.now() - start}')\n",
    "    print(f'Ended in {datetime.now() - initial_time}')\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a DataFrame with paths to unique pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/'\n",
    "\n",
    "pairs = ''\n",
    "with open(f'{dataset_path}pairs.txt', 'r') as file:\n",
    "    pairs = file.read()\n",
    "\n",
    "df = pd.DataFrame(list(map(lambda x: x.split('\\t'), pairs.split('\\n')[1:301])), columns=['name', 'pic1', 'pic2'])\n",
    "df = (pd.melt(df, id_vars='name', value_vars=['pic1', 'pic2'], var_name='picNum', value_name='pic')\n",
    "        .drop('picNum', axis=1)\n",
    "        .sort_values(by=['name', 'pic'])\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "df['pic'] = df['pic'].apply(lambda x: x.zfill(4))\n",
    "df['path_x1'] = str(dataset_path) + df['name'] + '/' + df['name'] + '_' + df['pic'] + '.jpg'\n",
    "\n",
    "df.to_csv('pics_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_to_scale_paths = df['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: get_basename(x) + '_result.jpg', pics_to_scale_paths))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating regular DataFrame for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_people_pics = []\n",
    "for name, name_df in df[['name', 'pic']].groupby('name'):\n",
    "    pics = name_df['pic'].values\n",
    "    pics_comb = list(it.combinations(pics, 2))\n",
    "    pics_name_comb = list(map(lambda x: [name]+[x[0]]+[name]+[x[1]], pics_comb))\n",
    "    for comb in pics_name_comb:\n",
    "        sim_people_pics.append(comb+[1])\n",
    "\n",
    "non_sim_people_pics = [el for el in it.combinations(df[['name', 'pic']].values.tolist(), 2) if el[0][0] != el[1][0]]\n",
    "non_sim_people_pics = [el[0]+el[1]+[0] for el in non_sim_people_pics]\n",
    "non_sim_people_pics = rnd.sample(non_sim_people_pics, len(sim_people_pics))\n",
    "\n",
    "classification_df = pd.DataFrame(sim_people_pics+non_sim_people_pics, \n",
    "                                 columns=['name_1', 'pic_1', 'name_2', 'pic_2', 'similarity'])\n",
    "\n",
    "classification_df.to_csv('classification_df.csv')\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = get_pathes(classification_df, df)\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_df = recognize_pics(classification_df, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df.to_csv('classification_df.csv')\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up-Scale and get perfomance of your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-Scale funcs of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can up-scale pics with different models and look at it's perfomance in recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_to_scale_paths = pd.read_csv('pics_df.csv', usecols=['path_x1'])['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: get_basename(x) + '_result.jpg', pics_to_scale_paths))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель DCSCN \n",
    "# Тут надо самому ставить нужный скейл: 2 3 или 4, так как памяти не хватает + настроить сохранение\n",
    "# в нужную папку сложна (не хочется заморачиваться), то надо перезапускать и руками переименовывать папку.\n",
    "\n",
    "model_name = 'DCSCN'\n",
    "scales = 4\n",
    "scaled_pics = os.listdir(f'{model_name}/output') # папка, в которой должны находиться апскейленные пикчи\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_paths):\n",
    "    if pic in scaled_pics: # зачастую случается OOM и чтобы заново не апскейлить уже апскейленные пикчи, чекаем их\n",
    "        continue\n",
    "    abc = f'--file={pic_path} --scale={scale}'\n",
    "    %run sr.py {abc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель ESRGAN\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import ESRGAN.architecture as arch\n",
    "\n",
    "model_path = 'ESRGAN/models/RRDB_ESRGAN_x4.pth' # sys.argv[1]  # models/RRDB_ESRGAN_x4.pth OR models/RRDB_PSNR_x4.pth\n",
    "device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n",
    "\n",
    "model = arch.RRDB_Net(3, 3, 64, 23, gc=32, upscale=4, norm_type=None, act_type='leakyrelu', \n",
    "                      mode='CNA', res_scale=1, upsample_mode='upconv')\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)\n",
    "\n",
    "scale = 4\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_paths):\n",
    "    img = cv2.imread(pic_path, cv2.IMREAD_COLOR)\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round()\n",
    "    cv2.imwrite(f'dataset/output_ESRGAN_x4/{pic}', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recognition perfomance of your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_perfomance(model_name, scales):\n",
    "    pics_df = pd.read_csv('pics_df.csv', index_col=0, dtype='object')\n",
    "    classification_df = pd.read_csv('classification_df.csv', index_col=0, dtype='object')\n",
    "    \n",
    "    model_pics_df = add_pathes(pics_df, scales, model_name)\n",
    "    model_classification_df = get_pathes(classification_df, model_pics_df)\n",
    "    \n",
    "    model_classification_df = recognize_pics(model_classification_df, scales)\n",
    "    model_classification_df.to_csv(f'classification_df_{model_name}.csv')\n",
    "    return model_classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [['No Scale',  [1]],\n",
    "          ['DCSCN',     [2, 3, 4]], \n",
    "          ['ESRGAN',    [4]],\n",
    "          ['EDSR',      [2, 3, 4]],\n",
    "          ['MDSR',      [2]],\n",
    "          ['SRFBN',     [2, 3, 4]],\n",
    "          ['SRFBN_BD',  [3]],\n",
    "          ['SRFBN_DN',  [3]],\n",
    "          ['DDSRCNN',   [2]],\n",
    "          ['DBPN',      [2, 4]],\n",
    "          ['proSR',     [2, 4]],\n",
    "          ['proSRGAN',  [4]],\n",
    "          ['proSRs',    [2, 4]],\n",
    "          ['DBPNLL',    [4]]\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[0] # No Scale\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[1] # DCSCN\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[2] # ESRGAN\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[3] # EDSR\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[4] # MDSR\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[5] # SRFBN\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[6] # SRFBN_BD\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[7] # SRFBN_DN\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[8] # DDSRCNN\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[9] # DBPN\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2019-06-05 22:00:22.012289\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Coding\\Person recognizer with Face Detection and Super-Resolution\\RECOGNIZER\\MTCNN\\layer_factory.py:221: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from RECOGNIZER/facenet_models/facenet/model-20180408-102900.ckpt-90\n",
      "Scale x2 started at 2019-06-05 22:00:48.458599\n",
      "Scale x2 is done in 0:17:23.770895\n",
      "Scale x4 started at 2019-06-05 22:18:12.229494\n",
      "Scale x4 is done in 0:52:31.309183\n",
      "Ended in 1:10:21.526388\n"
     ]
    }
   ],
   "source": [
    "model_name, scales = models[10] # proSR\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2019-06-05 23:10:43.698881\n",
      "INFO:tensorflow:Restoring parameters from RECOGNIZER/facenet_models/facenet/model-20180408-102900.ckpt-90\n",
      "Scale x4 started at 2019-06-05 23:11:06.769503\n",
      "Scale x4 is done in 0:51:16.752948\n",
      "Ended in 0:51:39.823570\n"
     ]
    }
   ],
   "source": [
    "model_name, scales = models[11] # proSRGAN\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[12] # proSRs\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[13] # DBPNLL\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the required metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>True Pos</th>\n",
       "      <th>False Pos</th>\n",
       "      <th>False Neg</th>\n",
       "      <th>True Neg</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MDSR</td>\n",
       "      <td>2</td>\n",
       "      <td>74.22</td>\n",
       "      <td>70.65</td>\n",
       "      <td>82.85</td>\n",
       "      <td>76.27</td>\n",
       "      <td>82.85</td>\n",
       "      <td>34.41</td>\n",
       "      <td>17.15</td>\n",
       "      <td>65.59</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCSCN</td>\n",
       "      <td>2</td>\n",
       "      <td>73.98</td>\n",
       "      <td>70.12</td>\n",
       "      <td>83.57</td>\n",
       "      <td>76.26</td>\n",
       "      <td>83.57</td>\n",
       "      <td>35.61</td>\n",
       "      <td>16.43</td>\n",
       "      <td>64.39</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DBPNLL</td>\n",
       "      <td>4</td>\n",
       "      <td>72.78</td>\n",
       "      <td>68.45</td>\n",
       "      <td>84.53</td>\n",
       "      <td>75.64</td>\n",
       "      <td>84.53</td>\n",
       "      <td>38.97</td>\n",
       "      <td>15.47</td>\n",
       "      <td>61.03</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Scale</td>\n",
       "      <td>1</td>\n",
       "      <td>73.68</td>\n",
       "      <td>70.72</td>\n",
       "      <td>80.82</td>\n",
       "      <td>75.43</td>\n",
       "      <td>80.82</td>\n",
       "      <td>33.45</td>\n",
       "      <td>19.18</td>\n",
       "      <td>66.55</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>proSRs</td>\n",
       "      <td>2</td>\n",
       "      <td>73.20</td>\n",
       "      <td>69.72</td>\n",
       "      <td>82.01</td>\n",
       "      <td>75.37</td>\n",
       "      <td>82.01</td>\n",
       "      <td>35.61</td>\n",
       "      <td>17.99</td>\n",
       "      <td>64.39</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DDSRCNN</td>\n",
       "      <td>2</td>\n",
       "      <td>73.56</td>\n",
       "      <td>70.20</td>\n",
       "      <td>81.89</td>\n",
       "      <td>75.59</td>\n",
       "      <td>81.89</td>\n",
       "      <td>34.77</td>\n",
       "      <td>18.11</td>\n",
       "      <td>65.23</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>proSR</td>\n",
       "      <td>2</td>\n",
       "      <td>72.84</td>\n",
       "      <td>69.26</td>\n",
       "      <td>82.13</td>\n",
       "      <td>75.15</td>\n",
       "      <td>82.13</td>\n",
       "      <td>36.45</td>\n",
       "      <td>17.87</td>\n",
       "      <td>63.55</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EDSR</td>\n",
       "      <td>4</td>\n",
       "      <td>72.36</td>\n",
       "      <td>68.09</td>\n",
       "      <td>84.17</td>\n",
       "      <td>75.28</td>\n",
       "      <td>84.17</td>\n",
       "      <td>39.45</td>\n",
       "      <td>15.83</td>\n",
       "      <td>60.55</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DCSCN</td>\n",
       "      <td>3</td>\n",
       "      <td>72.48</td>\n",
       "      <td>68.40</td>\n",
       "      <td>83.57</td>\n",
       "      <td>75.23</td>\n",
       "      <td>83.57</td>\n",
       "      <td>38.61</td>\n",
       "      <td>16.43</td>\n",
       "      <td>61.39</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DBPN</td>\n",
       "      <td>4</td>\n",
       "      <td>72.18</td>\n",
       "      <td>67.79</td>\n",
       "      <td>84.53</td>\n",
       "      <td>75.24</td>\n",
       "      <td>84.53</td>\n",
       "      <td>40.17</td>\n",
       "      <td>15.47</td>\n",
       "      <td>59.83</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>proSRs</td>\n",
       "      <td>4</td>\n",
       "      <td>72.12</td>\n",
       "      <td>67.72</td>\n",
       "      <td>84.53</td>\n",
       "      <td>75.20</td>\n",
       "      <td>84.53</td>\n",
       "      <td>40.29</td>\n",
       "      <td>15.47</td>\n",
       "      <td>59.71</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>proSRGAN</td>\n",
       "      <td>4</td>\n",
       "      <td>72.06</td>\n",
       "      <td>67.59</td>\n",
       "      <td>84.77</td>\n",
       "      <td>75.21</td>\n",
       "      <td>84.77</td>\n",
       "      <td>40.65</td>\n",
       "      <td>15.23</td>\n",
       "      <td>59.35</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SRFBN</td>\n",
       "      <td>2</td>\n",
       "      <td>72.42</td>\n",
       "      <td>68.93</td>\n",
       "      <td>81.65</td>\n",
       "      <td>74.75</td>\n",
       "      <td>81.65</td>\n",
       "      <td>36.81</td>\n",
       "      <td>18.35</td>\n",
       "      <td>63.19</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EDSR</td>\n",
       "      <td>2</td>\n",
       "      <td>72.30</td>\n",
       "      <td>68.67</td>\n",
       "      <td>82.01</td>\n",
       "      <td>74.75</td>\n",
       "      <td>82.01</td>\n",
       "      <td>37.41</td>\n",
       "      <td>17.99</td>\n",
       "      <td>62.59</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SRFBN</td>\n",
       "      <td>3</td>\n",
       "      <td>72.24</td>\n",
       "      <td>68.28</td>\n",
       "      <td>83.09</td>\n",
       "      <td>74.96</td>\n",
       "      <td>83.09</td>\n",
       "      <td>38.61</td>\n",
       "      <td>16.91</td>\n",
       "      <td>61.39</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DBPN</td>\n",
       "      <td>2</td>\n",
       "      <td>72.24</td>\n",
       "      <td>68.64</td>\n",
       "      <td>81.89</td>\n",
       "      <td>74.69</td>\n",
       "      <td>81.89</td>\n",
       "      <td>37.41</td>\n",
       "      <td>18.11</td>\n",
       "      <td>62.59</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESRGAN</td>\n",
       "      <td>4</td>\n",
       "      <td>72.00</td>\n",
       "      <td>67.59</td>\n",
       "      <td>84.53</td>\n",
       "      <td>75.12</td>\n",
       "      <td>84.53</td>\n",
       "      <td>40.53</td>\n",
       "      <td>15.47</td>\n",
       "      <td>59.47</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SRFBN_DN</td>\n",
       "      <td>3</td>\n",
       "      <td>71.70</td>\n",
       "      <td>66.92</td>\n",
       "      <td>85.85</td>\n",
       "      <td>75.21</td>\n",
       "      <td>85.85</td>\n",
       "      <td>42.45</td>\n",
       "      <td>14.15</td>\n",
       "      <td>57.55</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCSCN</td>\n",
       "      <td>4</td>\n",
       "      <td>71.94</td>\n",
       "      <td>67.73</td>\n",
       "      <td>83.81</td>\n",
       "      <td>74.92</td>\n",
       "      <td>83.81</td>\n",
       "      <td>39.93</td>\n",
       "      <td>16.19</td>\n",
       "      <td>60.07</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>proSR</td>\n",
       "      <td>4</td>\n",
       "      <td>71.76</td>\n",
       "      <td>67.54</td>\n",
       "      <td>83.81</td>\n",
       "      <td>74.80</td>\n",
       "      <td>83.81</td>\n",
       "      <td>40.29</td>\n",
       "      <td>16.19</td>\n",
       "      <td>59.71</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SRFBN_BD</td>\n",
       "      <td>3</td>\n",
       "      <td>70.20</td>\n",
       "      <td>65.44</td>\n",
       "      <td>85.61</td>\n",
       "      <td>74.18</td>\n",
       "      <td>85.61</td>\n",
       "      <td>45.20</td>\n",
       "      <td>14.39</td>\n",
       "      <td>54.80</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EDSR</td>\n",
       "      <td>3</td>\n",
       "      <td>71.76</td>\n",
       "      <td>67.78</td>\n",
       "      <td>82.97</td>\n",
       "      <td>74.61</td>\n",
       "      <td>82.97</td>\n",
       "      <td>39.45</td>\n",
       "      <td>17.03</td>\n",
       "      <td>60.55</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SRFBN</td>\n",
       "      <td>4</td>\n",
       "      <td>71.52</td>\n",
       "      <td>67.34</td>\n",
       "      <td>83.57</td>\n",
       "      <td>74.59</td>\n",
       "      <td>83.57</td>\n",
       "      <td>40.53</td>\n",
       "      <td>16.43</td>\n",
       "      <td>59.47</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Name  Scale  Accuracy  Precision  Recall     F1  True Pos  False Pos  \\\n",
       "8        MDSR      2     74.22      70.65   82.85  76.27     82.85      34.41   \n",
       "1       DCSCN      2     73.98      70.12   83.57  76.26     83.57      35.61   \n",
       "22     DBPNLL      4     72.78      68.45   84.53  75.64     84.53      38.97   \n",
       "0    No Scale      1     73.68      70.72   80.82  75.43     80.82      33.45   \n",
       "20     proSRs      2     73.20      69.72   82.01  75.37     82.01      35.61   \n",
       "14    DDSRCNN      2     73.56      70.20   81.89  75.59     81.89      34.77   \n",
       "17      proSR      2     72.84      69.26   82.13  75.15     82.13      36.45   \n",
       "7        EDSR      4     72.36      68.09   84.17  75.28     84.17      39.45   \n",
       "2       DCSCN      3     72.48      68.40   83.57  75.23     83.57      38.61   \n",
       "16       DBPN      4     72.18      67.79   84.53  75.24     84.53      40.17   \n",
       "21     proSRs      4     72.12      67.72   84.53  75.20     84.53      40.29   \n",
       "19   proSRGAN      4     72.06      67.59   84.77  75.21     84.77      40.65   \n",
       "9       SRFBN      2     72.42      68.93   81.65  74.75     81.65      36.81   \n",
       "5        EDSR      2     72.30      68.67   82.01  74.75     82.01      37.41   \n",
       "10      SRFBN      3     72.24      68.28   83.09  74.96     83.09      38.61   \n",
       "15       DBPN      2     72.24      68.64   81.89  74.69     81.89      37.41   \n",
       "4      ESRGAN      4     72.00      67.59   84.53  75.12     84.53      40.53   \n",
       "13   SRFBN_DN      3     71.70      66.92   85.85  75.21     85.85      42.45   \n",
       "3       DCSCN      4     71.94      67.73   83.81  74.92     83.81      39.93   \n",
       "18      proSR      4     71.76      67.54   83.81  74.80     83.81      40.29   \n",
       "12   SRFBN_BD      3     70.20      65.44   85.61  74.18     85.61      45.20   \n",
       "6        EDSR      3     71.76      67.78   82.97  74.61     82.97      39.45   \n",
       "11      SRFBN      4     71.52      67.34   83.57  74.59     83.57      40.53   \n",
       "\n",
       "    False Neg  True Neg  Rank  \n",
       "8       17.15     65.59  53.0  \n",
       "1       16.43     64.39  53.0  \n",
       "22      15.47     61.03  51.0  \n",
       "0       19.18     66.55  45.0  \n",
       "20      17.99     64.39  44.0  \n",
       "14      18.11     65.23  44.0  \n",
       "17      17.87     63.55  43.0  \n",
       "7       15.83     60.55  41.0  \n",
       "2       16.43     61.39  41.0  \n",
       "16      15.47     59.83  38.0  \n",
       "21      15.47     59.71  35.0  \n",
       "19      15.23     59.35  35.0  \n",
       "9       18.35     63.19  34.0  \n",
       "5       17.99     62.59  34.0  \n",
       "10      16.91     61.39  33.0  \n",
       "15      18.11     62.59  31.0  \n",
       "4       15.47     59.47  29.0  \n",
       "13      14.15     57.55  28.0  \n",
       "3       16.19     60.07  28.0  \n",
       "18      16.19     59.71  24.0  \n",
       "12      14.39     54.80  24.0  \n",
       "6       17.03     60.55  22.0  \n",
       "11      16.43     59.47  18.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for model_name, scales in models:\n",
    "    model_df = pd.read_csv(f'classification_df_{model_name}.csv', \n",
    "                           usecols=['similarity'] + [f'rec_x{scale}' for scale in scales])\n",
    "    rec_cols = model_df.columns[1:]\n",
    "    \n",
    "    model_accuracy = [round(accuracy_score(model_df['similarity'], model_df[col]) * 100, 2) for col in rec_cols]\n",
    "    model_precision = [round(precision_score(model_df['similarity'], model_df[col]) * 100, 2) for col in rec_cols]\n",
    "    model_recall = [round(recall_score(model_df['similarity'], model_df[col]) * 100, 2) for col in rec_cols]\n",
    "    model_f1 = [round(f1_score(model_df['similarity'], model_df[col]) * 100, 2) for col in rec_cols]\n",
    "    tn = [round(confusion_matrix(model_df['similarity'], model_df[col]).ravel()[0] / model_df.shape[0] * 200, 2) for col in rec_cols]\n",
    "    fp = [round(confusion_matrix(model_df['similarity'], model_df[col]).ravel()[1] / model_df.shape[0] * 200, 2) for col in rec_cols]\n",
    "    fn = [round(confusion_matrix(model_df['similarity'], model_df[col]).ravel()[2] / model_df.shape[0] * 200, 2) for col in rec_cols]\n",
    "    tp = [round(confusion_matrix(model_df['similarity'], model_df[col]).ravel()[3] / model_df.shape[0] * 200, 2) for col in rec_cols]\n",
    "\n",
    "    data_to_append = zip([model_name]*len(scales), scales, \n",
    "                         model_accuracy, model_precision, model_recall, model_f1, tp, fp, fn, tn)\n",
    "    metrics_df = metrics_df.append(list(data_to_append))\n",
    "metrics_df.reset_index(drop=True, inplace=True)\n",
    "metrics_df.columns = ['Model Name', 'Scale', 'Accuracy', 'Precision', 'Recall', 'F1', \n",
    "                      'True Pos', 'False Pos', 'False Neg', 'True Neg']\n",
    "metrics_df['Rank'] = sum([metrics_df[col].rank(method='first') for col in ['Accuracy', 'Precision', 'Recall']])\n",
    "metrics_df.to_excel('benchmark.xlsx')\n",
    "metrics_df.sort_values(by='Rank', ascending=False)\n",
    "# metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
