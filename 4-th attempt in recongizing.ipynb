{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run <b>3 cells below</b> and then <b>after <i>Up-Scale and get perfomance of your models</i></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import sys\n",
    "import os \n",
    "from datetime import datetime\n",
    "import random as rnd\n",
    "import itertools as it\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "from RECOGNIZER.recognizer import Recognizer\n",
    "from skimage.io import imread\n",
    "#--------------------------------------------------------------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basename(path): # dataset/lfw_funneled/Abel_Pacheco/Abel_Pacheco_0001.JPG -> Abel_Pacheco_0001\n",
    "    return os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "def add_pathes(df, scales, model_name): # (df, [2, 3, 4], 'DCSCN')\n",
    "    for scale in scales:\n",
    "        df[f'path_x{scale}'] = f'{model_name}/output_x{scale}/' + df[f'path_x1'].apply(get_basename) + '_result.jpg'\n",
    "    return df\n",
    "\n",
    "def get_pathes(classification_df, df):\n",
    "    for pic_num in [1, 2]:\n",
    "        classification_df = (pd.merge(classification_df, df, \n",
    "                                      left_on=[f'name_{pic_num}', f'pic_{pic_num}'], right_on=['name', 'pic'], \n",
    "                                      how='left', suffixes=('_1', '_2')))\n",
    "    classification_df = classification_df.loc[:, ~classification_df.columns.duplicated()]\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_pics(classification_df, scales):\n",
    "    initial_time = datetime.now() \n",
    "    print(f'Started at {initial_time}')\n",
    "\n",
    "    recognizer = Recognizer()\n",
    "    THRESHOLD = 0.9\n",
    "    \n",
    "    def recongize(row):\n",
    "        photo1 = imread(row.ix[0])\n",
    "        photo2 = imread(row.ix[1])\n",
    "        similarity = recognizer.get_best_similarity(photo1, photo2)\n",
    "        return 1 if similarity < THRESHOLD else 0\n",
    "\n",
    "    for scale in scales:\n",
    "        start = datetime.now()\n",
    "        print(f'Scale x{scale} started at {start}')\n",
    "        classification_df[f'rec_x{scale}'] = classification_df[[f'path_x{scale}_1', f'path_x{scale}_2']].apply(recongize, axis=1)\n",
    "        print(f'Scale x{scale} is done in {datetime.now() - start}')\n",
    "    print(f'Ended in {datetime.now() - initial_time}')\n",
    "    return classification_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a DataFrame with paths to unique pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/'\n",
    "\n",
    "pairs = ''\n",
    "with open(f'{dataset_path}pairs.txt', 'r') as file:\n",
    "    pairs = file.read()\n",
    "\n",
    "df = pd.DataFrame(list(map(lambda x: x.split('\\t'), pairs.split('\\n')[1:301])), columns=['name', 'pic1', 'pic2'])\n",
    "df = (pd.melt(df, id_vars='name', value_vars=['pic1', 'pic2'], var_name='picNum', value_name='pic')\n",
    "        .drop('picNum', axis=1)\n",
    "        .sort_values(by=['name', 'pic'])\n",
    "        .drop_duplicates()\n",
    "        .reset_index(drop=True))\n",
    "\n",
    "df['pic'] = df['pic'].apply(lambda x: x.zfill(4))\n",
    "df['path_x1'] = str(dataset_path) + df['name'] + '/' + df['name'] + '_' + df['pic'] + '.jpg'\n",
    "\n",
    "df.to_csv('pics_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_to_scale_paths = df['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: get_basename(x) + '_result.jpg', pics_to_scale_paths))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating regular DataFrame for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_people_pics = []\n",
    "for name, name_df in df[['name', 'pic']].groupby('name'):\n",
    "    pics = name_df['pic'].values\n",
    "    pics_comb = list(it.combinations(pics, 2))\n",
    "    pics_name_comb = list(map(lambda x: [name]+[x[0]]+[name]+[x[1]], pics_comb))\n",
    "    for comb in pics_name_comb:\n",
    "        sim_people_pics.append(comb+[1])\n",
    "\n",
    "non_sim_people_pics = [el for el in it.combinations(df[['name', 'pic']].values.tolist(), 2) if el[0][0] != el[1][0]]\n",
    "non_sim_people_pics = [el[0]+el[1]+[0] for el in non_sim_people_pics]\n",
    "non_sim_people_pics = rnd.sample(non_sim_people_pics, len(sim_people_pics))\n",
    "\n",
    "classification_df = pd.DataFrame(sim_people_pics+non_sim_people_pics, \n",
    "                                 columns=['name_1', 'pic_1', 'name_2', 'pic_2', 'similarity'])\n",
    "\n",
    "classification_df.to_csv('classification_df.csv')\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = get_pathes(classification_df, df)\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classification_df = recognize_pics(classification_df, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df.to_csv('classification_df.csv')\n",
    "classification_df.iloc[[0, 1, 2, -3, -2, -1], :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up-Scale and get perfomance of your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Up-Scale funcs of different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can up-scale pics with different models and look at it's perfomance in recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_to_scale_paths = pd.read_csv('pics_df.csv', usecols=['path_x1'])['path_x1'].values\n",
    "pics_to_scale = list(map(lambda x: get_basename(x) + '_result.jpg', pics_to_scale_paths))\n",
    "print(f'There are {len(pics_to_scale)} unique pics to be scaled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель DCSCN \n",
    "# Тут надо самому ставить нужный скейл: 2 3 или 4, так как памяти не хватает + настроить сохранение\n",
    "# в нужную папку сложна (не хочется заморачиваться), то надо перезапускать и руками переименовывать папку.\n",
    "\n",
    "model_name = 'DCSCN'\n",
    "scales = 4\n",
    "scaled_pics = os.listdir(f'{model_name}/output') # папка, в которой должны находиться апскейленные пикчи\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_paths):\n",
    "    if pic in scaled_pics: # зачастую случается OOM и чтобы заново не апскейлить уже апскейленные пикчи, чекаем их\n",
    "        continue\n",
    "    abc = f'--file={pic_path} --scale={scale}'\n",
    "    %run sr.py {abc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модель ESRGAN\n",
    "import glob\n",
    "import cv2\n",
    "import torch\n",
    "import ESRGAN.architecture as arch\n",
    "\n",
    "model_path = 'ESRGAN/models/RRDB_ESRGAN_x4.pth' # sys.argv[1]  # models/RRDB_ESRGAN_x4.pth OR models/RRDB_PSNR_x4.pth\n",
    "device = torch.device('cuda')  # if you want to run on CPU, change 'cuda' -> cpu\n",
    "\n",
    "model = arch.RRDB_Net(3, 3, 64, 23, gc=32, upscale=4, norm_type=None, act_type='leakyrelu', \n",
    "                      mode='CNA', res_scale=1, upsample_mode='upconv')\n",
    "model.load_state_dict(torch.load(model_path), strict=True)\n",
    "model.eval()\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = False\n",
    "model = model.to(device)\n",
    "\n",
    "scale = 4\n",
    "for pic, pic_path in zip(pics_to_scale, pics_to_scale_paths):\n",
    "    img = cv2.imread(pic_path, cv2.IMREAD_COLOR)\n",
    "    img = img * 1.0 / 255\n",
    "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
    "    img_LR = img.unsqueeze(0)\n",
    "    img_LR = img_LR.to(device)\n",
    "\n",
    "    output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
    "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
    "    output = (output * 255.0).round()\n",
    "    cv2.imwrite(f'dataset/output_ESRGAN_x4/{pic}', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR UP-SCALE FUNCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recognition perfomance of your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_perfomance(model_name, scales):\n",
    "    pics_df = pd.read_csv('pics_df.csv', index_col=0, dtype='object')\n",
    "    classification_df = pd.read_csv('classification_df.csv', index_col=0, dtype='object')\n",
    "    \n",
    "    model_pics_df = add_pathes(pics_df, scales, model_name)\n",
    "    model_classification_df = get_pathes(classification_df, model_pics_df)\n",
    "    \n",
    "    model_classification_df = recognize_pics(model_classification_df, scales)\n",
    "    model_classification_df.to_csv(f'classification_df_{model_name}.csv')\n",
    "    return model_classification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [['DCSCN', [2, 3, 4]], \n",
    "          ['ESRGAN', [4]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[0]\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name, scales = models[1]\n",
    "model_df = get_rec_perfomance(model_name, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the required metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>scale</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DCSCN</td>\n",
       "      <td>1</td>\n",
       "      <td>73.68</td>\n",
       "      <td>70.72</td>\n",
       "      <td>80.82</td>\n",
       "      <td>75.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCSCN</td>\n",
       "      <td>2</td>\n",
       "      <td>73.98</td>\n",
       "      <td>70.12</td>\n",
       "      <td>83.57</td>\n",
       "      <td>76.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DCSCN</td>\n",
       "      <td>3</td>\n",
       "      <td>72.48</td>\n",
       "      <td>68.40</td>\n",
       "      <td>83.57</td>\n",
       "      <td>75.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCSCN</td>\n",
       "      <td>4</td>\n",
       "      <td>71.94</td>\n",
       "      <td>67.73</td>\n",
       "      <td>83.81</td>\n",
       "      <td>74.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESRGAN</td>\n",
       "      <td>1</td>\n",
       "      <td>73.68</td>\n",
       "      <td>70.72</td>\n",
       "      <td>80.82</td>\n",
       "      <td>75.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ESRGAN</td>\n",
       "      <td>4</td>\n",
       "      <td>72.00</td>\n",
       "      <td>67.59</td>\n",
       "      <td>84.53</td>\n",
       "      <td>75.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  scale  accuracy  precision  recall     f1\n",
       "0      DCSCN      1     73.68      70.72   80.82  75.43\n",
       "1      DCSCN      2     73.98      70.12   83.57  76.26\n",
       "2      DCSCN      3     72.48      68.40   83.57  75.23\n",
       "3      DCSCN      4     71.94      67.73   83.81  74.92\n",
       "4     ESRGAN      1     73.68      70.72   80.82  75.43\n",
       "5     ESRGAN      4     72.00      67.59   84.53  75.12"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame()\n",
    "\n",
    "for model_name, scales in models:\n",
    "    scales = [1] + scales\n",
    "    model_df = pd.read_csv(f'classification_df_{model_name}.csv', \n",
    "                           usecols=['similarity'] + [f'rec_x{scale}' for scale in scales])\n",
    "    rec_cols = model_df.columns[1:]\n",
    "    \n",
    "    model_accuracy = [round(accuracy_score(model_df['similarity'], model_df[col]) * 100, 2) for col in rec_cols]\n",
    "    model_precision = [round(precision_score(model_df['similarity'], model_df[col]) * 100, 2) for col in rec_cols]\n",
    "    model_recall = [round(recall_score(model_df['similarity'], model_df[col]) * 100, 2) for col in rec_cols]\n",
    "    model_f1 = [round(f1_score(model_df['similarity'], model_df[col]) * 100, 2) for col in rec_cols]\n",
    "\n",
    "    data_to_append = zip([model_name]*len(scales), scales, \n",
    "                         model_accuracy, model_precision, model_recall, model_f1)\n",
    "    metrics_df = metrics_df.append(list(data_to_append))\n",
    "metrics_df.reset_index(drop=True, inplace=True)\n",
    "metrics_df.columns = ['model_name', 'scale', 'accuracy', 'precision', 'recall', 'f1']\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
